{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773b6225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Your code\n",
    "from byscratch.linear_algebra import Vector, Matrix\n",
    "from byscratch.linear_algebra import make_matrix\n",
    "from byscratch.linear_algebra import sum_of_squares\n",
    "from byscratch.linear_algebra import dot\n",
    "from byscratch.linear_algebra import subtract\n",
    "from byscratch.linear_algebra import magnitude\n",
    "from byscratch.linear_algebra import scalar_multiply\n",
    "from byscratch.linear_algebra import vector_mean\n",
    "from byscratch.linear_algebra import distance\n",
    "from byscratch.linear_algebra import add\n",
    "\n",
    "from byscratch.statistics import correlation\n",
    "from byscratch.statistics import standard_deviation\n",
    "from byscratch.statistics import median\n",
    "from byscratch.statistics import mean\n",
    "from byscratch.statistics import de_mean\n",
    "from byscratch.statistics import standard_deviation\n",
    "\n",
    "\n",
    "\n",
    "from byscratch.gradient_descent import gradient_step\n",
    "\n",
    "from byscratch.probability import inverse_normal_cdf\n",
    "\n",
    "from byscratch.working_with_data import rescale\n",
    "\n",
    "\n",
    "# python library imports\n",
    "import random, datetime, re, csv, math, enum\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "from typing import Tuple, List, NamedTuple, Optional, Callable\n",
    "from typing import TypeVar, List, Iterator\n",
    "\n",
    "# external code\n",
    "from dateutil.parser import parse\n",
    "import tqdm\n",
    "\n",
    "# pyplot configs\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# font\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "\n",
    "# reset the default figsize value\n",
    "plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
    "\n",
    "# 144 is good for a high-resolution display. Try 100 if it's too big\n",
    "plt.rcParams[\"figure.dpi\"] = (80)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/nickcrites/Desktop/byscratch/Data/bike_sharing_daily.csv')\n",
    "\n",
    "df_less = df.loc[df['income'] == '<=50K'].sample(n=11200)\n",
    "df_more = df.loc[df['income'] == '>50K'].sample(n=11200)\n",
    "\n",
    "df_less.shape, df_more.shape\n",
    "\n",
    "df_stratifiedincome = pd.concat([df_less,df_more])\n",
    "df_stratifiedincome.to_csv('byscratch/data/adult_stratified_income.csv')\n",
    "\n",
    "df_stratifiedincome.shape\n",
    "\n",
    "# show the first two rows: header and data\n",
    "!head -1 'byscratch/data/adult_stratified_income.csv' > cols.txt ;\n",
    "# !cat cols.txt\n",
    "\n",
    "with open(\"cols.txt\") as f:\n",
    "    for line in f:\n",
    "        cols = line.strip().split(',')\n",
    "\n",
    "print(\"| i | col |\")\n",
    "print(\"|-- |---- |\")\n",
    "for i,c in enumerate(cols):\n",
    "  print(f\"| {i} | {c} |\")\n",
    "\n",
    "# Get the shape of this dataset\n",
    "filename = \"byscratch/data/adult_stratified_income.csv\"\n",
    "with open(filename) as f:\n",
    "    numlines = sum(1 for line in f)\n",
    "\n",
    "numlines\n",
    "\n",
    "# Load up a large data structure\n",
    "data_dict = csv.DictReader(open(filename))\n",
    "\n",
    "# Let's do some frequency counting\n",
    "from collections import Counter\n",
    "\n",
    "# race, gender, occupation, hours worked per week, and education\n",
    "ages = []\n",
    "races = []\n",
    "genders = []\n",
    "incomes = []\n",
    "educationalnum = []\n",
    "occupations = []\n",
    "hoursperweek = []\n",
    "\n",
    "for row in data_dict:\n",
    "    ags = int(row[\"age\"])\n",
    "    ages.append(ags)\n",
    "\n",
    "    hours = int(row[\"hours-per-week\"])\n",
    "    hoursperweek.append(hours)\n",
    "\n",
    "    race = str(row[\"race\"])\n",
    "    races.append(race)\n",
    "\n",
    "    gender = str(row[\"gender\"])\n",
    "    genders.append(gender)\n",
    "\n",
    "    income = str(row[\"income\"])\n",
    "    incomes.append(income)\n",
    "\n",
    "    occupation = str(row[\"occupation\"])\n",
    "    occupations.append(occupation)\n",
    "\n",
    "    education = str(row[\"educational-num\"])\n",
    "    educationalnum.append(int(education))\n",
    "\n",
    "assert len(educationalnum) == len(hoursperweek) == len(races) == len(genders) == len(incomes) == len(occupations)\n",
    "\n",
    "# SANITY CHECK Use your code to get the mean & median hours per week\n",
    "print(f\"The mean hours-per-week is {mean(hoursperweek)}, median is {median(hoursperweek)}\")\n",
    "\n",
    "print(f\"The mean age is {mean(ages)}, median is {median(ages)}\")\n",
    "\n",
    "print(f\"The mean work hours per week is {mean(hoursperweek)}, median is {median(hoursperweek)}\")\n",
    "\n",
    "\n",
    "# Create dictionaries of frequency counts for ordinals. \n",
    "# Order the keys\n",
    "\n",
    "def orderedCounter(alist):\n",
    "    c = Counter(alist)\n",
    "    ld = dict((str(k).lower(), v) for k, v in c.items())\n",
    "    old = OrderedDict(sorted(ld.items()))\n",
    "    return old\n",
    "\n",
    "def orderedCounterInt(alist):\n",
    "    c = Counter(alist)\n",
    "    ld = dict((int(k), v) for k, v in c.items())\n",
    "    s = sorted(ld.items())\n",
    "    # print(s)\n",
    "    old = OrderedDict(sorted(s))\n",
    "    return old\n",
    "\n",
    "# distribution of incomes? \n",
    "inc = orderedCounter(incomes)\n",
    "\n",
    "sns.barplot(\n",
    "    y=list(inc.keys()),\n",
    "    x=list(inc.values()),\n",
    "    orient='h')\n",
    "\n",
    "plt.title(\"We sampled the dataset so there are equal numbers of each group\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Ages histplot\n",
    "\n",
    "sns.histplot(ages,binwidth=5)\n",
    "\n",
    "plt.title(\"Histogram plot showing the distribution of ages, binwidth = 5yrs\")\n",
    "plt.show()\n",
    "\n",
    "# distribution of education?\n",
    "edu = orderedCounterInt(educationalnum)\n",
    "\n",
    "sns.barplot(\n",
    "    y=list(edu.keys()),\n",
    "    x=list(edu.values()),\n",
    "    orient='h')\n",
    "\n",
    "plt.title(\"Number of adults vs. years of education completed\")\n",
    "plt.show()\n",
    "\n",
    "o = orderedCounter(occupations)\n",
    "\n",
    "sns.barplot(\n",
    "    y=list(o.keys()),\n",
    "    x=list(o.values()),\n",
    "    orient='h')\n",
    "\n",
    "plt.title(\"Number of adults employed in each job type\")\n",
    "plt.show()\n",
    "\n",
    "# Distribution of race?\n",
    "r = orderedCounter(races)\n",
    "\n",
    "sns.barplot(\n",
    "    y=list(r.keys()),\n",
    "    x=list(r.values()),\n",
    "    orient='h')\n",
    "\n",
    "plt.title(\"Distribution of race\")\n",
    "plt.show()\n",
    "\n",
    "# distribution of gender?\n",
    "g = orderedCounter(genders)\n",
    "\n",
    "sns.barplot(\n",
    "    y=list(g.keys()),\n",
    "    x=list(g.values()),\n",
    "    orient='h')\n",
    "\n",
    "plt.title(\"Distribution of gender\")\n",
    "plt.show()\n",
    "\n",
    "def col2index(d,m):\n",
    "    # Python 3.6+ retains the order of dictionaries\n",
    "    i=0\n",
    "    for k,v in d.items():\n",
    "        if k.lower() == m.lower():\n",
    "            return i\n",
    "        else:\n",
    "            i = i+1\n",
    "\n",
    "vec = []\n",
    "X = []  # vector\n",
    "y = []  # target\n",
    "# encode the ordinals\n",
    "for j in range(len(hoursperweek)):\n",
    "    # Arrrggggh! We want the index, not the value!\n",
    "    k=races[j]\n",
    "    race = col2index(r,k)\n",
    "    k=genders[j]\n",
    "    gender = col2index(g,k)\n",
    "    k=occupations[j]\n",
    "    occupation = col2index(o,k)\n",
    "    k=incomes[j]\n",
    "    income=col2index(inc,k)\n",
    "    education=educationalnum[j]\n",
    "    age=ages[j]\n",
    "\n",
    "    \n",
    "    vec.append( (income,[age,gender,race,education,occupation]) )\n",
    "\n",
    "import random\n",
    "from byscratch.machine_learning import split_data\n",
    "\n",
    "train,test = split_data(vec,0.75)\n",
    "len(test),len(train)\n",
    "\n",
    "\n",
    "y_train = [t[0] for t in train]\n",
    "X_train = [t[1] for t in train]\n",
    "\n",
    "y_test = [t[0] for t in test]\n",
    "X_test = [t[1] for t in test]\n",
    "\n",
    "# train should have more items, right?\n",
    "len(X_train),len(X_test)\n",
    "\n",
    "\n",
    "# What is the best value for k?'\n",
    "# Try the elbow method\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "numpts = 25\n",
    "error_rate = []\n",
    "error_rate1 = []\n",
    "\n",
    "# This might take some time!\n",
    "for i in range(1,numpts):\n",
    "  knn = KNeighborsClassifier(n_neighbors=i)\n",
    "  knn.fit(X_train,y_train)\n",
    "  pred_i = knn.predict(X_test)\n",
    "  error_rate.append(np.mean(pred_i != y_test))\n",
    "  pred_j = knn.predict(X_train)\n",
    "  error_rate1.append(np.mean(pred_j != y_train))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,numpts),error_rate,color='blue', \n",
    "         linestyle='dashed', marker='o',markerfacecolor='red', markersize=7)\n",
    "plt.plot(range(1,numpts),error_rate1,color='gray', \n",
    "         linestyle='dashed', marker='^',markerfacecolor='green', markersize=7)\n",
    "\n",
    "plt.legend(['testing data','training data'])\n",
    "plt.title('Error Rate vs. value of k')\n",
    "plt.xlabel('k value')\n",
    "plt.ylabel('Error Rate')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "k = 17\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "knn.score(X_train,y_train), knn.score(X_test,y_test)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        knn,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=['<50k','>50k'],\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    # print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "sklearn.__version__\n",
    "\n",
    "##Pandas Bayesian analysis\n",
    "\n",
    "col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',\n",
    "             'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n",
    "\n",
    "df.columns = col_names\n",
    "\n",
    "df.columns\n",
    "\n",
    "# I cleaned out the Null values before we started\n",
    "df.isnull().sum()\n",
    "\n",
    "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
    "\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "\n",
    "print('The categorical variables are :\\n\\n', categorical)\n",
    "\n",
    "# As above -- no Nulls expected\n",
    "df[categorical].isnull().sum()\n",
    "\n",
    "\n",
    "# Let's drop the education and fnlwgt columns\n",
    "df=df.drop(['education','fnlwgt'],axis=1)\n",
    "\n",
    "# the data\n",
    "X = df.drop(['income'], axis=1)\n",
    "\n",
    "# the target\n",
    "y = df['income']\n",
    "\n",
    "# convert ordinal data (or \"features\" !) to numbers\n",
    "# compare the methods above\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "df['workclass'] = le.fit_transform(df['workclass'])\n",
    "df['marital_status'] = le.fit_transform(df['marital_status'])\n",
    "df['occupation'] = le.fit_transform(df['occupation'])\n",
    "df['relationship'] = le.fit_transform(df['relationship'])\n",
    "df['race'] = le.fit_transform(df['race'])\n",
    "df['sex'] = le.fit_transform(df['sex'])\n",
    "df['native_country'] = le.fit_transform(df['native_country'])\n",
    "df['income'] = le.fit_transform(df['income'])\n",
    "\n",
    "df.head()\n",
    "\n",
    "sns.barplot(x='income',y='age',data=df);\n",
    "\n",
    "sns.barplot(x='relationship',y='race',data=df);\n",
    "\n",
    "# what two features correlate the most? least?\n",
    "sns.heatmap(df.corr())\n",
    "\n",
    "X=df.drop(['income'],axis=1)\n",
    "y=df['income']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25)\n",
    "\n",
    "# train should have more items, right?\n",
    "len(X_train),len(X_test)\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# instantiate the model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# fit the model\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "titles_options = [\n",
    "    (\"Confusion matrix, without normalization\", None),\n",
    "    (\"Normalized confusion matrix\", \"true\"),\n",
    "]\n",
    "for title, normalize in titles_options:\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        gnb,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=['<50k','>50k'],\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize=normalize,\n",
    "    )\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    # print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
